{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAgsAKZ+rjfTTXtSVn4xEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogeshsinghgit/Pwskills_Assignment/blob/main/Na%C3%AFve_bayes_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naïve bayes-Assignment 1\n",
        "\n",
        "[Assignment Link ](https://drive.google.com/drive/folders/1AvhkFT1KRCvLFhuGyp37lpsrqRmU2dFy)"
      ],
      "metadata": {
        "id": "VN8-4pfRSiMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. What is Bayes' theorem?"
      ],
      "metadata": {
        "id": "ujKkYVvySdZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes Theorem is a method to determine conditional probabilities – that is, the probability of one event occurring given that another event has already occurred. Because a conditional probability includes additional conditions – in other words, more data – it can contribute to more accurate results.\n",
        "\n",
        "Bayes Theorem states:\n",
        "\n",
        "P(H | X) = [ P(X | H) * P(H) ] / P(X)"
      ],
      "metadata": {
        "id": "rETKVNUmSsIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. What is the formula for Bayes' theorem?"
      ],
      "metadata": {
        "id": "oweM8sfzTSqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes' theorem is a fundamental theorem in probability theory that relates the probability of an event based on prior knowledge of conditions that might be related to the event. The formula for Bayes' theorem is as follows:\n",
        "\n",
        "$[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} ]$\n",
        "\n",
        "In this formula:\n",
        "\n",
        "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred.\n",
        "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred.\n",
        "- \\( P(A) \\) is the prior probability of event A.\n",
        "- \\( P(B) \\) is the prior probability of event B.\n",
        "\n",
        "The theorem allows you to update your beliefs about the probability of event A based on new evidence provided by event B."
      ],
      "metadata": {
        "id": "D_hgXWpjTTsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3. How is Bayes' theorem used in practice?"
      ],
      "metadata": {
        "id": "qK13mSZLT4ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes' theorem is widely used in various fields and applications, including statistics, machine learning, medical diagnosis, information retrieval, and more. Its application can be summarized in the following steps:\n",
        "\n",
        "1. **Define Events and Prior Probabilities:**\n",
        "   - Identify the events of interest, A and B.\n",
        "   - Determine the prior probabilities \\( P(A) \\) and \\( P(B) \\).\n",
        "\n",
        "2. **Collect Data:**\n",
        "   - Gather relevant data or evidence that might be related to the events A and B.\n",
        "\n",
        "3. **Calculate Likelihood:**\n",
        "   - Calculate the likelihood $( P(B|A) )$, the probability of observing the evidence B given that A has occurred.\n",
        "\n",
        "4. **Update Prior Probability:**\n",
        "   - Use Bayes' theorem to update the prior probability $( P(A) )$ based on the new evidence:\n",
        "     $[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}]$\n",
        "\n",
        "5. **Calculate Normalizing Constant:**\n",
        "   - Calculate the normalizing constant $( P(B) )$ to ensure that the probabilities sum to 1:\n",
        "     $[ P(B) = P(B|A) \\cdot P(A) + P(B|\\neg A) \\cdot P(\\neg A)]$\n",
        "   where $( \\neg A )$ represents the complement of event A.\n",
        "\n",
        "6. **Interpret Results:**\n",
        "   - The updated probability \\( P(A|B) \\) represents the revised probability of event A occurring given the new evidence B.\n",
        "\n",
        "### Example:\n",
        "Suppose you want to diagnose a medical condition (event A) based on a set of symptoms (event B). Bayes' theorem can help update the probability of the condition given the observed symptoms.\n",
        "\n",
        "- \\( P(A) \\): Prior probability of the medical condition.\n",
        "- \\( P(B|A) \\): Likelihood of observing the symptoms given the condition.\n",
        "- \\( P(A|B) \\): Updated probability of the condition given the observed symptoms.\n",
        "\n",
        "By iteratively applying Bayes' theorem as more evidence becomes available, the probability estimate can be refined and adjusted based on the cumulative information."
      ],
      "metadata": {
        "id": "oFmXISmQUCrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4. What is the relationship between Bayes' theorem and conditional probability?"
      ],
      "metadata": {
        "id": "OZzfLDewTxLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes' theorem is closely related to conditional probability, and it can be derived from the definition of conditional probability. Let's start with the definition of conditional probability:\n",
        "\n",
        "\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\]\n",
        "\n",
        "Here, \\( P(A|B) \\) represents the probability of event A occurring given that event B has occurred, \\( P(A \\cap B) \\) is the probability of both A and B occurring, and \\( P(B) \\) is the probability of event B occurring.\n",
        "\n",
        "Now, we can express \\( P(A \\cap B) \\) in terms of conditional probability:\n",
        "\n",
        "\\[ P(A \\cap B) = P(A|B) \\cdot P(B) \\]\n",
        "\n",
        "Substituting this into the conditional probability formula, we get:\n",
        "\n",
        "\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A|B) \\cdot P(B)}{P(B)} \\]\n",
        "\n",
        "Simplifying, we arrive at Bayes' theorem:\n",
        "\n",
        "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
        "\n",
        "In summary, Bayes' theorem is a way of expressing conditional probability in terms of other probabilities. It provides a systematic method for updating probabilities based on new evidence or information, making it a powerful tool in various fields, especially in the context of inference and decision-making under uncertainty."
      ],
      "metadata": {
        "id": "7C0pFJS4UqAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
      ],
      "metadata": {
        "id": "Q6cP7lSwUxOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The type of distribution and dataset, defines the type of Naive Bayes Classifier we use.\n",
        "\n",
        "1. If the distribution is Gaussian Then we use Gaussian Naive Bayes\n",
        "\n",
        "2. If the distribution is Bernoulli, Then we use Bernoulli Naive Bayes\n",
        "\n",
        "3. If the datset has text values, then we use Multinomial Naive Bayes."
      ],
      "metadata": {
        "id": "aEMG17QGU8j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. Assignment:\n",
        "\n",
        "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
        "Bayes to classify a new instance with features X1 = 3 and X2 = 4.\n",
        "\n",
        "The following table shows the frequency of\n",
        "each feature value for each class:\n",
        "\n",
        "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
        "\n",
        "A 3 3 4 4 3 3 3\n",
        "\n",
        "B 2 2 1 2 2 2 3\n",
        "\n",
        "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
        "to belong to?"
      ],
      "metadata": {
        "id": "nx72u2-MVtgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm leaving the question as it is because I'm not able to understand the features values, a nice table will make it more easy to understand."
      ],
      "metadata": {
        "id": "l3Pg3_jlW0FC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cnp4kmYVrBs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}